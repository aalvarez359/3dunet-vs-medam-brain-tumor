{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNEJGeZMNHJ3BHTfker/eNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalvarez359/3dunet-vs-medam-brain-tumor/blob/main/training%20/unet_msd_training/3d_unet_msd_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Scripts 1,2 for 4 modality msd unet\n",
        "\n",
        "Run Scripts 1,2 and 5 for flair-only msd unet\n",
        "\n",
        "Run Scripts 1,2 and 6 for t2f or t2w brats2024\n",
        "\n",
        "Make sure your directories are pointed to the right place\n"
      ],
      "metadata": {
        "id": "pJPgNFmKa1nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "2zvZI77Egf-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxG8-JqlZRYy",
        "outputId": "f693c06d-ff6f-4d8b-fe79-51058e67e7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2"
      ],
      "metadata": {
        "id": "NgVnFEBngl3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nibabel segmentation-models-pytorch-3d torch torchvision torchaudio tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsjwHn5aA0qn",
        "outputId": "0652a3bf-a92c-43e6-d521-97b73c2e522e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (5.3.2)\n",
            "Collecting segmentation-models-pytorch-3d\n",
            "  Downloading segmentation_models_pytorch_3d-1.0.2-py3-none-any.whl.metadata (724 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nibabel) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel) (4.15.0)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch-3d)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch-3d)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.7 (from segmentation-models-pytorch-3d)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm-3d==1.0.1 (from segmentation-models-pytorch-3d)\n",
            "  Downloading timm_3d-1.0.1-py3-none-any.whl.metadata (588 bytes)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch-3d) (11.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch-3d) (1.17.0)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch-3d)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm==0.9.7->segmentation-models-pytorch-3d) (6.0.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from timm==0.9.7->segmentation-models-pytorch-3d) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm==0.9.7->segmentation-models-pytorch-3d) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation-models-pytorch-3d) (2025.11.12)\n",
            "Downloading segmentation_models_pytorch_3d-1.0.2-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm_3d-1.0.1-py3-none-any.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.8/626.8 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=011e792113f4ca8eb0fe9935f3f8478d4c14e2be6f352c5b243e4990de3d8d08\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/3f/43/e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=14cd1cbe9586e23af5f8318e4cf089e9e03e13c8fbdb22088af90f39f9918556\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/01/56/40a48f75dbdfe167a0cb70d3b48913369a00ec5c4e9fed5f2b\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm-3d, timm, pretrainedmodels, segmentation-models-pytorch-3d\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.22\n",
            "    Uninstalling timm-1.0.22:\n",
            "      Successfully uninstalled timm-1.0.22\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-3d-1.0.2 timm-0.9.7 timm-3d-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "-i6O7hhUgply"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Your actual root with all the BraTS-GLI-xxxxx-yyy folders\n",
        "BRATS2024_ROOT = \"/content/drive/MyDrive/BraTS2024_TrainingData_extracted/BraTS2024-BraTS-GLI-TrainingData/training_data1_v2\"\n",
        "\n",
        "# Where to save the dataset JSON\n",
        "JSON_PATH_BRATS2024 = os.path.join(BRATS2024_ROOT, \"dataset_brats2024_cases.json\")\n",
        "\n",
        "cases = []\n",
        "\n",
        "for root, dirs, files in os.walk(BRATS2024_ROOT):\n",
        "    for f in files:\n",
        "        if f.endswith(\"-seg.nii.gz\"):\n",
        "            seg_path = os.path.join(root, f)\n",
        "            base = f[:-len(\"-seg.nii.gz\")]  # e.g. BraTS-GLI-02077-100\n",
        "\n",
        "            # Expected modality paths for this case\n",
        "            t2f_path = os.path.join(root, base + \"-t2f.nii.gz\")  # FLAIR-like\n",
        "            t2w_path = os.path.join(root, base + \"-t2w.nii.gz\")\n",
        "            t1c_path = os.path.join(root, base + \"-t1c.nii.gz\")\n",
        "            t1n_path = os.path.join(root, base + \"-t1n.nii.gz\")\n",
        "\n",
        "            # Require at least FLAIR + seg\n",
        "            if not (os.path.exists(t2f_path) and os.path.exists(seg_path)):\n",
        "                print(\"Skipping (missing FLAIR or seg):\", base)\n",
        "                continue\n",
        "\n",
        "            case = {\n",
        "                \"case_id\": base,\n",
        "                \"seg\": seg_path,\n",
        "                \"t2f\": t2f_path,\n",
        "                \"t2w\": t2w_path if os.path.exists(t2w_path) else None,\n",
        "                \"t1c\": t1c_path if os.path.exists(t1c_path) else None,\n",
        "                \"t1n\": t1n_path if os.path.exists(t1n_path) else None,\n",
        "            }\n",
        "            cases.append(case)\n",
        "\n",
        "print(f\"Found {len(cases)} cases with FLAIR + seg.\")\n",
        "\n",
        "dataset = {\"training\": cases}\n",
        "\n",
        "# Make sure directory for JSON exists\n",
        "os.makedirs(os.path.dirname(JSON_PATH_BRATS2024), exist_ok=True)\n",
        "\n",
        "with open(JSON_PATH_BRATS2024, \"w\") as f:\n",
        "    json.dump(dataset, f, indent=2)\n",
        "\n",
        "print(\"Saved dataset JSON to:\", JSON_PATH_BRATS2024)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki91awMxlXLj",
        "outputId": "cc24a7f8-75c9-46f6-ea7f-14e7fba8ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1350 cases with FLAIR + seg.\n",
            "Saved dataset JSON to: /content/drive/MyDrive/BraTS2024_TrainingData_extracted/BraTS2024-BraTS-GLI-TrainingData/training_data1_v2/dataset_brats2024_cases.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4"
      ],
      "metadata": {
        "id": "b6OnZwqDgxrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 modality 3D U-Net\n",
        "import os, json, time, math, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "#!pip install nibabel segmentation-models-pytorch-3d torch torchvision torchaudio tqdm\n",
        "# pip install segmentation-models-pytorch-3d nibabel tqdm\n",
        "import segmentation_models_pytorch_3d as smp3d\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "JSON_PATH = \"/content/drive/MyDrive/Task01_BrainTumour_extracted/Task01_BrainTumour/dataset.json\"   # path to your JSON\n",
        "# SAVE_DIR  = \"checkpoints_smp3d_b7\" # Original save directory\n",
        "SAVE_DIR  = \"/content/drive/MyDrive/BrainTumor_Checkpoints\" # Save to Google Drive\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "#TRAIN_VAL_SPLIT = 0.90\n",
        "\n",
        "# Compute & memory knobs (safe for Colab 16GB VRAM)\n",
        "PATCH_SIZE = (128, 224, 224)       # training crop + SWI window\n",
        "#PATCH_SIZE = (128, 192, 192)\n",
        "OVERLAP    = 0.75               # sliding-window overlap\n",
        "#OVERLAP    = 0.5\n",
        "#BATCH_SIZE = 2                # L4 GPU\n",
        "BATCH_SIZE = 6                # A100 GPU\n",
        "ACCUM_STEPS = 1                # A100 GPU\n",
        "#ACCUM_STEPS = 4                # L4 GPU\n",
        "#NUM_WORKERS = 2                 #L4 GPU\n",
        "NUM_WORKERS = 4                 #A100\n",
        "\n",
        "# Training schedule\n",
        "EPOCHS = 75\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Data/spec\n",
        "IN_CHANNELS = 4                 # (FLAIR, T1w, T1gd, T2w)\n",
        "N_CLASSES   = 4                 # (bg, edema, non-enh, enh)\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility\n",
        "# -------------------------\n",
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s)\n",
        "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "set_seed()\n",
        "\n",
        "torch.backends.cudnn.benchmark = True      # faster on fixed-size inputs\n",
        "torch.backends.cudnn.deterministic = False # allow fastest algorithms\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# NIfTI I/O + preprocessing\n",
        "# -------------------------\n",
        "def percentile_clip(arr, lo=0.5, hi=99.5):\n",
        "    a = arr.astype(np.float32)\n",
        "    l, h = np.percentile(a, [lo, hi]); a = np.clip(a, l, h)\n",
        "    return a\n",
        "\n",
        "def zscore_per_channel(x, eps=1e-8):\n",
        "    # x: (C, D, H, W)\n",
        "    x = x.astype(np.float32)\n",
        "    for c in range(x.shape[0]):\n",
        "        v = x[c]\n",
        "        mask = (v != 0)\n",
        "        m = v[mask].mean() if mask.any() else v.mean()\n",
        "        s = v[mask].std()  if mask.any() else v.std()\n",
        "        s = max(float(s), eps)\n",
        "        x[c] = (v - m) / s\n",
        "    return x\n",
        "\n",
        "def load_nifti_image_chwd(path_img):\n",
        "    # BRATS-like: (H, W, D, 4) -> (C=4, D, H, W)\n",
        "    img = nib.load(str(path_img))\n",
        "    arr = img.get_fdata(dtype=np.float32)\n",
        "    assert arr.ndim == 4 and arr.shape[3] == IN_CHANNELS, f\"{path_img} shape {arr.shape} not HWD4\"\n",
        "    chans = [percentile_clip(arr[..., c], 0.5, 99.5) for c in range(arr.shape[3])]\n",
        "    vol = np.stack(chans, axis=3)                 # H W D C\n",
        "    vol = np.transpose(vol, (3, 2, 0, 1))         # C D H W\n",
        "    vol = zscore_per_channel(vol)\n",
        "    return vol\n",
        "\n",
        "def load_nifti_label_dhw(path_lab):\n",
        "    lab = nib.load(str(path_lab)).get_fdata(dtype=np.float32)  # H W D\n",
        "    lab = np.rint(lab).astype(np.int64)\n",
        "    lab = np.transpose(lab, (2, 0, 1))  # D H W\n",
        "    return lab\n",
        "\n",
        "# -------------------------\n",
        "# Cropping & SW Inference\n",
        "# -------------------------\n",
        "def random_crop_3d(image_cdhw, label_dhw, crop, tries=8, fg_bias=0.5):\n",
        "    C, D, H, W = image_cdhw.shape\n",
        "    cd, ch, cw = crop\n",
        "    assert D >= cd and H >= ch and W >= cw, f\"Patch {crop} > vol {(D,H,W)}\"\n",
        "    for _ in range(tries):\n",
        "        z0 = np.random.randint(0, D - cd + 1)\n",
        "        y0 = np.random.randint(0, H - ch + 1)\n",
        "        x0 = np.random.randint(0, W - cw + 1)\n",
        "        patch_lab = label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "        if (np.random.rand() > fg_bias) or np.any(patch_lab > 0):\n",
        "            return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], patch_lab\n",
        "    # fallback random\n",
        "    z0 = np.random.randint(0, D - cd + 1)\n",
        "    y0 = np.random.randint(0, H - ch + 1)\n",
        "    x0 = np.random.randint(0, W - cw + 1)\n",
        "    return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "\n",
        "@torch.no_grad()\n",
        "def sliding_window_inference(volume_cdhw, model, window, overlap, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    C, D, H, W = volume_cdhw.shape\n",
        "    wd, wh, ww = window\n",
        "    sd = max(1, int(wd * (1 - overlap)))\n",
        "    sh = max(1, int(wh * (1 - overlap)))\n",
        "    sw = max(1, int(ww * (1 - overlap)))\n",
        "\n",
        "    out_prob = torch.zeros((N_CLASSES, D, H, W), dtype=torch.float32, device=device)\n",
        "    out_norm = torch.zeros((1, D, H, W), dtype=torch.float32, device=device)\n",
        "\n",
        "    for z in range(0, max(D - wd + 1, 1), sd):\n",
        "        z0 = min(z, D - wd)\n",
        "        for y in range(0, max(H - wh + 1, 1), sh):\n",
        "            y0 = min(y, H - wh)\n",
        "            for x in range(0, max(W - ww + 1, 1), sw):\n",
        "                x0 = min(x, W - ww)\n",
        "                patch = volume_cdhw[:, z0:z0+wd, y0:y0+wh, x0:x0+ww]\n",
        "                pt = torch.from_numpy(patch).unsqueeze(0).to(device)  # 1,C,D,H,W\n",
        "                logits = model(pt)                                    # 1,C,d,h,w\n",
        "                probs = F.softmax(logits, dim=1)[0]\n",
        "                out_prob[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += probs\n",
        "                out_norm[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += 1.0\n",
        "\n",
        "    out_prob /= (out_norm + 1e-8)\n",
        "    pred = torch.argmax(out_prob, dim=0)  # D H W\n",
        "    return pred, out_prob\n",
        "\n",
        "# -------------------------\n",
        "# Dataset\n",
        "# -------------------------\n",
        "class BratsTrainPatches(Dataset):\n",
        "    def __init__(self, items):\n",
        "        self.items = items\n",
        "\n",
        "    def __len__(self): return len(self.items)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        it  = self.items[i]\n",
        "        img = load_nifti_image_chwd(it[\"image\"])  # C D H W\n",
        "        lab = load_nifti_label_dhw(it[\"label\"])   # D H W\n",
        "\n",
        "        # Foreground-biased random crop\n",
        "        img, lab = random_crop_3d(img, lab, PATCH_SIZE, fg_bias=0.85)\n",
        "\n",
        "        # --- Geometric augmentations ---\n",
        "        # Rotate ONLY in-plane (H, W) → keeps shape (C, D, H, W) consistent\n",
        "        if np.random.rand() < 0.5:\n",
        "            k = np.random.randint(0, 4)\n",
        "            img = np.rot90(img, k=k, axes=(2, 3)).copy()  # rotate over H,W\n",
        "            lab = np.rot90(lab, k=k, axes=(1, 2)).copy()  # rotate over H,W\n",
        "\n",
        "        # Flips along depth, height, width (safe for shapes)\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=1).copy()  # flip D\n",
        "            lab = np.flip(lab, axis=0).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=2).copy()  # flip H\n",
        "            lab = np.flip(lab, axis=1).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=3).copy()  # flip W\n",
        "            lab = np.flip(lab, axis=2).copy()\n",
        "\n",
        "        # --- Light intensity augmentations ---\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img * (0.9 + 0.2 * np.random.rand())\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img + np.random.normal(0, 0.05, img.shape).astype(np.float32)\n",
        "\n",
        "        # Return torch tensors\n",
        "        return torch.from_numpy(img), torch.from_numpy(lab).long()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Losses & Metrics\n",
        "# -------------------------\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0, include_bg=False):\n",
        "        super().__init__(); self.smooth = smooth; self.include_bg = include_bg\n",
        "    def forward(self, logits, targets):\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        N, C, D, H, W = probs.shape\n",
        "        onehot = torch.zeros_like(probs)\n",
        "        onehot.scatter_(1, targets.unsqueeze(1), 1)\n",
        "        s = 0 if self.include_bg else 1\n",
        "        p = probs[:, s:, ...]; t = onehot[:, s:, ...]\n",
        "        dims = (0,2,3,4)\n",
        "        inter = torch.sum(p*t, dims); denom = torch.sum(p+t, dims)\n",
        "        dice = (2.0*inter + self.smooth) / (denom + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "class CEDice(nn.Module):\n",
        "    def __init__(self, w_ce=1.0, w_dice=1.0, include_bg_dice=False):\n",
        "        super().__init__(); self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = SoftDiceLoss(include_bg=include_bg_dice)\n",
        "        self.w_ce = w_ce; self.w_dice = w_dice\n",
        "    def forward(self, logits, y):\n",
        "        return self.w_ce*self.ce(logits, y) + self.w_dice*self.dice(logits, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_per_class(pred, target, n_classes=N_CLASSES):\n",
        "    if pred.ndim == 3:\n",
        "        pred = pred.unsqueeze(0); target = target.unsqueeze(0)\n",
        "    out = []\n",
        "    for c in range(n_classes):\n",
        "        p = (pred == c); t = (target == c)\n",
        "        inter = (p & t).sum().item(); denom = p.sum().item()+t.sum().item()\n",
        "        out.append((2*inter/denom) if denom>0 else 1.0)\n",
        "    return out\n",
        "\n",
        "# -------------------------\n",
        "# Data split from JSON\n",
        "# -------------------------\n",
        "def load_train_val_from_json(json_path, train_frac=0.75, val_frac=0.05):\n",
        "    \"\"\"\n",
        "    Split MSD training set into train / val / test.\n",
        "\n",
        "    - train_frac: fraction of total for training\n",
        "    - val_frac  : fraction of total for validation\n",
        "    - test_frac : remainder (1 - train_frac - val_frac)\n",
        "\n",
        "    We do this ONLY once; afterward we always reload the same split\n",
        "    from dataset_split.json in SAVE_DIR so that U-Net and MedSAM2\n",
        "    share the exact same test set.\n",
        "    \"\"\"\n",
        "    split_path = os.path.join(SAVE_DIR, \"dataset_split.json\")\n",
        "\n",
        "    # ---- 1) If split already exists, just reload it (LOCKED SPLIT) ----\n",
        "    if os.path.exists(split_path):\n",
        "        with open(split_path, \"r\") as f:\n",
        "            split = json.load(f)\n",
        "        train_items = split[\"train\"]\n",
        "        val_items   = split[\"val\"]\n",
        "        test_items  = split[\"test\"]\n",
        "        print(f\"Loaded existing dataset split from {split_path}\")\n",
        "        print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "        return train_items, val_items, test_items\n",
        "\n",
        "    # ---- 2) Otherwise, create a new split and save it ----\n",
        "    with open(json_path, \"r\") as f:\n",
        "        js = json.load(f)\n",
        "\n",
        "    items = js[\"training\"]  # list of {\"image\":..., \"label\":...}\n",
        "    root = Path(json_path).parent\n",
        "\n",
        "    # Make image/label paths absolute so they remain valid when reloaded\n",
        "    for it in items:\n",
        "        it[\"image\"] = str((root / it[\"image\"]).resolve())\n",
        "        it[\"label\"] = str((root / it[\"label\"]).resolve())\n",
        "\n",
        "    n = len(items)\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.RandomState(SEED)\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    n_train = int(n * train_frac)\n",
        "    n_val   = int(n * val_frac)\n",
        "    n_test  = n - n_train - n_val\n",
        "\n",
        "    train_idx = idx[:n_train]\n",
        "    val_idx   = idx[n_train:n_train + n_val]\n",
        "    test_idx  = idx[n_train + n_val:]\n",
        "\n",
        "    train_items = [items[i] for i in train_idx]\n",
        "    val_items   = [items[i] for i in val_idx]\n",
        "    test_items  = [items[i] for i in test_idx]\n",
        "\n",
        "    split = {\n",
        "        \"train\": train_items,\n",
        "        \"val\":   val_items,\n",
        "        \"test\":  test_items,\n",
        "    }\n",
        "    with open(split_path, \"w\") as f:\n",
        "        json.dump(split, f, indent=2)\n",
        "    print(f\"Saved dataset split listing to {split_path}\")\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "\n",
        "    return train_items, val_items, test_items\n",
        "\n",
        "# -------------------------\n",
        "# Model\n",
        "# -------------------------\n",
        "def build_model(device):\n",
        "    model = smp3d.Unet(\n",
        "        encoder_name=\"efficientnet-b7\",\n",
        "        encoder_weights=None,\n",
        "        in_channels=IN_CHANNELS,\n",
        "        classes=N_CLASSES,\n",
        "        # slimmer decoder to save VRAM\n",
        "        decoder_channels=(192, 128, 64, 32, 16),\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Validation\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def validate_full_volume(model, val_items, device):\n",
        "    model.eval()\n",
        "\n",
        "    mean_dice_all = []          # Existing behavior: mean of classes 1-3\n",
        "    per_class_dice = {1: [], 2: [], 3: []}  # ✅ New: collect per-tumor-class Dice scores\n",
        "\n",
        "    for it in tqdm(val_items, desc=\"Validating (full-volume)\", leave=False):\n",
        "        vol = load_nifti_image_chwd(it[\"image\"])      # C D H W\n",
        "        lab = load_nifti_label_dhw(it[\"label\"])       # D H W\n",
        "\n",
        "        # ---- Run sliding-window prediction ----\n",
        "        pred, _ = sliding_window_inference(vol, model, PATCH_SIZE, OVERLAP, device)\n",
        "\n",
        "        # ---- Compute Dice per class ----\n",
        "        dices = dice_per_class(pred.cpu(), torch.from_numpy(lab))\n",
        "        # dices is assumed to be a tensor/list of 4 values: [bg, class1, class2, class3]\n",
        "\n",
        "        # ✅ Append mean over non-background classes (1–3), same as before\n",
        "        mean_dice_all.append(np.mean(dices[1:]))\n",
        "\n",
        "        # ✅ Store per-class Dice for logging later\n",
        "        for cls in [1, 2, 3]:\n",
        "            per_class_dice[cls].append(float(dices[cls]))\n",
        "\n",
        "    # ✅ Compute final averages\n",
        "    final_mean_dice = float(np.mean(mean_dice_all))\n",
        "    final_per_class_dice = {\n",
        "        cls: float(np.mean(per_class_dice[cls])) for cls in [1, 2, 3]\n",
        "    }\n",
        "\n",
        "    # ✅ You can return both\n",
        "    return final_mean_dice, final_per_class_dice\n",
        "\n",
        "def save_checkpoint(path, epoch, model, opt, sched, scaler, best_val):\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": opt.state_dict(),\n",
        "            \"scheduler\": sched.state_dict(),\n",
        "            \"scaler\": scaler.state_dict(),\n",
        "            \"best_val\": float(best_val),\n",
        "            \"config\": {\n",
        "                \"encoder\": \"efficientnet-b7\",\n",
        "                \"in_channels\": IN_CHANNELS,\n",
        "                \"classes\": N_CLASSES,\n",
        "                \"patch_size\": PATCH_SIZE,\n",
        "            },\n",
        "        },\n",
        "        path,\n",
        "    )\n",
        "\n",
        "def resume_if_possible(model, opt, sched, scaler, load_scheduler=False):\n",
        "    \"\"\"Load last.pt if it exists and return (start_epoch, best_val).\"\"\"\n",
        "    last_ckpt = os.path.join(SAVE_DIR, \"last.pt\")\n",
        "    if os.path.exists(last_ckpt):\n",
        "        ckpt = torch.load(last_ckpt, map_location=\"cpu\")\n",
        "\n",
        "        # weights\n",
        "        model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "        # optimizer\n",
        "        if \"optimizer\" in ckpt:\n",
        "            opt.load_state_dict(ckpt[\"optimizer\"])\n",
        "\n",
        "        # scheduler (optional, but we keep it False when switching to OneCycle)\n",
        "        if load_scheduler and \"scheduler\" in ckpt and sched is not None:\n",
        "            try:\n",
        "                sched.load_state_dict(ckpt[\"scheduler\"])\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ Skipping scheduler state load:\", e)\n",
        "\n",
        "        # scaler\n",
        "        if \"scaler\" in ckpt:\n",
        "            scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "\n",
        "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "        best_val = float(ckpt.get(\"best_val\", -1.0))\n",
        "        print(f\"↩ Resumed from {last_ckpt}: start_epoch={start_epoch}, best_val={best_val:.4f}\")\n",
        "        return start_epoch, best_val\n",
        "    return 1, -1.0\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Train loop\n",
        "# -------------------------\n",
        "def train():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    # 3-way split: train / val / test\n",
        "    train_items, val_items, test_items = load_train_val_from_json(JSON_PATH, train_frac=0.75, val_frac=0.05)\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "\n",
        "    train_ds = BratsTrainPatches(train_items)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=(device==\"cuda\"), drop_last=True)\n",
        "\n",
        "    model = build_model(device)\n",
        "    loss_fn = CEDice(w_ce=1.0, w_dice=1.0, include_bg_dice=False)\n",
        "    cls_w = torch.tensor([1.0, 2.0, 2.3, 1.2], device=device)\n",
        "    loss_fn.ce = nn.CrossEntropyLoss(weight=cls_w, label_smoothing=0.03)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    #sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "    sched = None\n",
        "    scaler = GradScaler(device=\"cuda\")\n",
        "\n",
        "    start_epoch, best_val = resume_if_possible(model, opt, sched, scaler, load_scheduler=False)\n",
        "\n",
        "    # ---- Build OneCycleLR for the remaining epochs ----\n",
        "    # IMPORTANT: OneCycle expects *optimizer step count* per epoch, not dataloader iters,\n",
        "    # so we divide by ACCUM_STEPS (ceil).\n",
        "    steps_per_epoch = len(train_loader) // ACCUM_STEPS\n",
        "    remaining_epochs = max(1, EPOCHS - (start_epoch - 1))  # e.g., 160 - 103 + 1 if resuming at 103\n",
        "\n",
        "    # Optional: make sure LR is at your intended max before OneCycle constructs its curve\n",
        "    for pg in opt.param_groups:\n",
        "        pg['lr'] = LR\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        opt,\n",
        "        max_lr=LR,\n",
        "        steps_per_epoch=steps_per_epoch,   # number of optimizer.step() calls per epoch\n",
        "        epochs=remaining_epochs,\n",
        "        pct_start=0.1,\n",
        "        div_factor=10,\n",
        "        final_div_factor=100,\n",
        "    )\n",
        "\n",
        "    # ---- init or load training history (for nice plots and resume) ----\n",
        "    history_path = os.path.join(SAVE_DIR, \"training_history.json\")\n",
        "    if os.path.exists(history_path):\n",
        "        with open(history_path, \"r\") as f:\n",
        "            history = json.load(f)\n",
        "    else:\n",
        "        history = {\n",
        "            \"epoch\": [],\n",
        "            \"train_loss\": [],\n",
        "            \"val_mean_dice\": [],\n",
        "            \"dice_edema\": [],\n",
        "            \"dice_non_enh\": [],\n",
        "            \"dice_enh\": [],\n",
        "            \"lr\": []\n",
        "        }\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(start_epoch, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "        running = 0.0\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        for i, (x, y) in enumerate(pbar):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(device_type=\"cuda\"):\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y) / ACCUM_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if ((i+1) % ACCUM_STEPS) == 0:\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True)\n",
        "\n",
        "                sched.step()\n",
        "\n",
        "            running += loss.item() * ACCUM_STEPS\n",
        "            pbar.set_postfix(loss=f\"{(running/(i+1)):.4f}\")\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        train_loss = running / max(1, len(train_loader))\n",
        "        # --- Validation ---\n",
        "        val_mean_dice, per_class = validate_full_volume(model, val_items, device)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        print(f\"[{epoch:03d}] \"\n",
        "            f\"train_loss={train_loss:.4f}  \"\n",
        "            f\"val_meanDice(no-bg)={val_mean_dice:.4f}  \"\n",
        "            f\"Dice(edema)={per_class[1]:.4f}  \"\n",
        "            f\"Dice(non-enh)={per_class[2]:.4f}  \"\n",
        "            f\"Dice(enh)={per_class[3]:.4f}  \"\n",
        "            f\"lr={sched.get_last_lr()[0]:.2e}  ({dt:.1f}s)\")\n",
        "\n",
        "        # ---- Save training history for plotting ----\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_mean_dice\"].append(val_mean_dice)\n",
        "        history[\"dice_edema\"].append(per_class[1])\n",
        "        history[\"dice_non_enh\"].append(per_class[2])\n",
        "        history[\"dice_enh\"].append(per_class[3])\n",
        "        history[\"lr\"].append(sched.get_last_lr()[0])\n",
        "\n",
        "        with open(os.path.join(SAVE_DIR, \"training_history.json\"), \"w\") as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "\n",
        "        # save last\n",
        "        save_checkpoint(\n",
        "            os.path.join(SAVE_DIR, \"last.pt\"),\n",
        "            epoch, model, opt, sched, scaler, best_val\n",
        ")\n",
        "\n",
        "        # save best\n",
        "        if val_mean_dice > best_val:\n",
        "            best_val = val_mean_dice\n",
        "            best_path = os.path.join(SAVE_DIR, f\"best_epoch{epoch}_dice{best_val:.4f}.pt\")\n",
        "            save_checkpoint(best_path, epoch, model, opt, sched, scaler, best_val)\n",
        "            print(\"✔ Saved\", best_path)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Best val mean Dice (no-bg): {best_val:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "metadata": {
        "id": "VxDrmGyo7cni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "28939977-a7d6-4ca1-c9f1-4efd9d8d719d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loaded existing dataset split from /content/drive/MyDrive/BrainTumor_Checkpoints/dataset_split.json\n",
            "Train=363  Val=24  Test=97\n",
            "Train=363  Val=24  Test=97\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2173424575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2173424575.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_if_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# ---- Build OneCycleLR for the remaining epochs ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2173424575.py\u001b[0m in \u001b[0;36mresume_if_possible\u001b[0;34m(model, opt, sched, scaler, load_scheduler)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mlast_ckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;31m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;31m# Read the first few bytes and match against the ZIP file signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mlocal_header_magic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mread_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_header_magic_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_bytes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlocal_header_magic_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5"
      ],
      "metadata": {
        "id": "tLTKr3Ijg2eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FLAIR-only MSD 3D U-Net\n",
        "\n",
        "import os, json, time, math, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "# !pip install nibabel segmentation-models-pytorch-3d torch torchvision torchaudio tqdm\n",
        "import segmentation_models_pytorch_3d as smp3d\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# --- Paths ---\n",
        "JSON_PATH = \"/content/drive/MyDrive/Task01_BrainTumour_extracted/Task01_BrainTumour/dataset.json\"   # original MSD/BRATS json\n",
        "\n",
        "# ✅ Reuse the SAME split as your 4-modality experiment:\n",
        "SPLIT_JSON_PATH = \"/content/drive/MyDrive/BrainTumor_Checkpoints/dataset_split.json\"\n",
        "\n",
        "# ✅ Save FLAIR-only checkpoints in a different folder\n",
        "SAVE_DIR  = \"/content/drive/MyDrive/BrainTumor_Checkpoints_FLAIR\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# Compute & memory knobs (copied from your 4-mod script)\n",
        "PATCH_SIZE = (128, 224, 224)       # training crop + SWI window\n",
        "OVERLAP    = 0.75                  # sliding-window overlap\n",
        "BATCH_SIZE = 6                     # A100 GPU (worked for your 4-mod run)\n",
        "ACCUM_STEPS = 1\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Training schedule\n",
        "EPOCHS = 95\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Data/spec\n",
        "IN_CHANNELS = 1                 # ✅ FLAIR only now\n",
        "N_CLASSES   = 4                 # (bg, edema, non-enh, enh)\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility\n",
        "# -------------------------\n",
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s)\n",
        "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "set_seed()\n",
        "\n",
        "torch.backends.cudnn.benchmark = True      # faster on fixed-size inputs\n",
        "torch.backends.cudnn.deterministic = False # allow fastest algorithms\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# NIfTI I/O + preprocessing\n",
        "# -------------------------\n",
        "def percentile_clip(arr, lo=0.5, hi=99.5):\n",
        "    a = arr.astype(np.float32)\n",
        "    l, h = np.percentile(a, [lo, hi]); a = np.clip(a, l, h)\n",
        "    return a\n",
        "\n",
        "def zscore_per_channel(x, eps=1e-8):\n",
        "    # x: (C, D, H, W)\n",
        "    x = x.astype(np.float32)\n",
        "    for c in range(x.shape[0]):\n",
        "        v = x[c]\n",
        "        mask = (v != 0)\n",
        "        m = v[mask].mean() if mask.any() else v.mean()\n",
        "        s = v[mask].std()  if mask.any() else v.std()\n",
        "        s = max(float(s), eps)\n",
        "        x[c] = (v - m) / s\n",
        "    return x\n",
        "\n",
        "def load_nifti_image_chwd(path_img):\n",
        "    \"\"\"\n",
        "    FLAIR-only loader.\n",
        "\n",
        "    Original BRATS: (H, W, D, 4)\n",
        "      - we now take ONLY channel 0 (FLAIR)\n",
        "      - -> (H, W, D)\n",
        "      - -> (C=1, D, H, W)\n",
        "    \"\"\"\n",
        "    img = nib.load(str(path_img))\n",
        "    arr = img.get_fdata(dtype=np.float32)   # (H, W, D, 4) in BRATS/Task01\n",
        "    assert arr.ndim == 4 and arr.shape[3] >= 1, f\"{path_img} shape {arr.shape} not HWD4\"\n",
        "\n",
        "    flair = percentile_clip(arr[..., 0], 0.5, 99.5)  # channel 0 = FLAIR, shape (H, W, D)\n",
        "\n",
        "    # add channel axis → (H, W, D, 1)\n",
        "    vol = flair[..., None]                      # (H, W, D, 1)\n",
        "    vol = np.transpose(vol, (3, 2, 0, 1))       # (C=1, D, H, W)\n",
        "    vol = zscore_per_channel(vol)\n",
        "    return vol\n",
        "\n",
        "def load_nifti_label_dhw(path_lab):\n",
        "    lab = nib.load(str(path_lab)).get_fdata(dtype=np.float32)  # H W D\n",
        "    lab = np.rint(lab).astype(np.int64)\n",
        "    lab = np.transpose(lab, (2, 0, 1))  # D H W\n",
        "    return lab\n",
        "\n",
        "# -------------------------\n",
        "# Cropping & SW Inference\n",
        "# -------------------------\n",
        "def random_crop_3d(image_cdhw, label_dhw, crop, tries=8, fg_bias=0.5):\n",
        "    C, D, H, W = image_cdhw.shape\n",
        "    cd, ch, cw = crop\n",
        "    assert D >= cd and H >= ch and W >= cw, f\"Patch {crop} > vol {(D,H,W)}\"\n",
        "    for _ in range(tries):\n",
        "        z0 = np.random.randint(0, D - cd + 1)\n",
        "        y0 = np.random.randint(0, H - ch + 1)\n",
        "        x0 = np.random.randint(0, W - cw + 1)\n",
        "        patch_lab = label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "        if (np.random.rand() > fg_bias) or np.any(patch_lab > 0):\n",
        "            return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], patch_lab\n",
        "    # fallback random\n",
        "    z0 = np.random.randint(0, D - cd + 1)\n",
        "    y0 = np.random.randint(0, H - ch + 1)\n",
        "    x0 = np.random.randint(0, W - cw + 1)\n",
        "    return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "\n",
        "@torch.no_grad()\n",
        "def sliding_window_inference(volume_cdhw, model, window, overlap, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    C, D, H, W = volume_cdhw.shape\n",
        "    wd, wh, ww = window\n",
        "    sd = max(1, int(wd * (1 - overlap)))\n",
        "    sh = max(1, int(wh * (1 - overlap)))\n",
        "    sw = max(1, int(ww * (1 - overlap)))\n",
        "\n",
        "    out_prob = torch.zeros((N_CLASSES, D, H, W), dtype=torch.float32, device=device)\n",
        "    out_norm = torch.zeros((1, D, H, W), dtype=torch.float32, device=device)\n",
        "\n",
        "    for z in range(0, max(D - wd + 1, 1), sd):\n",
        "        z0 = min(z, D - wd)\n",
        "        for y in range(0, max(H - wh + 1, 1), sh):\n",
        "            y0 = min(y, H - wh)\n",
        "            for x in range(0, max(W - ww + 1, 1), sw):\n",
        "                x0 = min(x, W - ww)\n",
        "                patch = volume_cdhw[:, z0:z0+wd, y0:y0+wh, x0:x0+ww]\n",
        "                pt = torch.from_numpy(patch).unsqueeze(0).to(device)  # 1,C,D,H,W\n",
        "                logits = model(pt)                                    # 1,C,d,h,w\n",
        "                probs = F.softmax(logits, dim=1)[0]\n",
        "                out_prob[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += probs\n",
        "                out_norm[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += 1.0\n",
        "\n",
        "    out_prob /= (out_norm + 1e-8)\n",
        "    pred = torch.argmax(out_prob, dim=0)  # D H W\n",
        "    return pred, out_prob\n",
        "\n",
        "# -------------------------\n",
        "# Dataset\n",
        "# -------------------------\n",
        "class BratsTrainPatches(Dataset):\n",
        "    def __init__(self, items):\n",
        "        self.items = items\n",
        "\n",
        "    def __len__(self): return len(self.items)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        it  = self.items[i]\n",
        "        img = load_nifti_image_chwd(it[\"image\"])  # C D H W (now C=1)\n",
        "        lab = load_nifti_label_dhw(it[\"label\"])   # D H W\n",
        "\n",
        "        # Foreground-biased random crop\n",
        "        img, lab = random_crop_3d(img, lab, PATCH_SIZE, fg_bias=0.85)\n",
        "\n",
        "        # --- Geometric augmentations ---\n",
        "        # Rotate ONLY in-plane (H, W) → keeps shape (C, D, H, W) consistent\n",
        "        if np.random.rand() < 0.5:\n",
        "            k = np.random.randint(0, 4)\n",
        "            img = np.rot90(img, k=k, axes=(2, 3)).copy()  # rotate over H,W\n",
        "            lab = np.rot90(lab, k=k, axes=(1, 2)).copy()  # rotate over H,W\n",
        "\n",
        "        # Flips along depth, height, width (safe for shapes)\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=1).copy()  # flip D\n",
        "            lab = np.flip(lab, axis=0).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=2).copy()  # flip H\n",
        "            lab = np.flip(lab, axis=1).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=3).copy()  # flip W\n",
        "            lab = np.flip(lab, axis=2).copy()\n",
        "\n",
        "        # --- Light intensity augmentations ---\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img * (0.9 + 0.2 * np.random.rand())\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img + np.random.normal(0, 0.05, img.shape).astype(np.float32)\n",
        "\n",
        "        # Return torch tensors\n",
        "        return torch.from_numpy(img), torch.from_numpy(lab).long()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Losses & Metrics\n",
        "# -------------------------\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0, include_bg=False):\n",
        "        super().__init__(); self.smooth = smooth; self.include_bg = include_bg\n",
        "    def forward(self, logits, targets):\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        N, C, D, H, W = probs.shape\n",
        "        onehot = torch.zeros_like(probs)\n",
        "        onehot.scatter_(1, targets.unsqueeze(1), 1)\n",
        "        s = 0 if self.include_bg else 1\n",
        "        p = probs[:, s:, ...]; t = onehot[:, s:, ...]\n",
        "        dims = (0,2,3,4)\n",
        "        inter = torch.sum(p*t, dims); denom = torch.sum(p+t, dims)\n",
        "        dice = (2.0*inter + self.smooth) / (denom + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "class CEDice(nn.Module):\n",
        "    def __init__(self, w_ce=1.0, w_dice=1.0, include_bg_dice=False):\n",
        "        super().__init__(); self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = SoftDiceLoss(include_bg=include_bg_dice)\n",
        "        self.w_ce = w_ce; self.w_dice = w_dice\n",
        "    def forward(self, logits, y):\n",
        "        return self.w_ce*self.ce(logits, y) + self.w_dice*self.dice(logits, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_per_class(pred, target, n_classes=N_CLASSES):\n",
        "    if pred.ndim == 3:\n",
        "        pred = pred.unsqueeze(0); target = target.unsqueeze(0)\n",
        "    out = []\n",
        "    for c in range(n_classes):\n",
        "        p = (pred == c); t = (target == c)\n",
        "        inter = (p & t).sum().item(); denom = p.sum().item()+t.sum().item()\n",
        "        out.append((2*inter/denom) if denom>0 else 1.0)\n",
        "    return out\n",
        "\n",
        "# -------------------------\n",
        "# Data split from JSON\n",
        "# -------------------------\n",
        "def load_train_val_from_json(json_path, train_frac=0.75, val_frac=0.05):\n",
        "    \"\"\"\n",
        "    FLAIR-only version:\n",
        "    ✅ Always reuse the EXISTING split from your 4-modality run.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(SPLIT_JSON_PATH), f\"Split file not found: {SPLIT_JSON_PATH}\"\n",
        "    with open(SPLIT_JSON_PATH, \"r\") as f:\n",
        "        split = json.load(f)\n",
        "    train_items = split[\"train\"]\n",
        "    val_items   = split[\"val\"]\n",
        "    test_items  = split[\"test\"]\n",
        "    print(f\"Loaded existing dataset split from {SPLIT_JSON_PATH}\")\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "    return train_items, val_items, test_items\n",
        "\n",
        "# -------------------------\n",
        "# Model (hard-coded B7)\n",
        "# -------------------------\n",
        "def build_model(device):\n",
        "    model = smp3d.Unet(\n",
        "        encoder_name=\"efficientnet-b7\",\n",
        "        encoder_weights=None,\n",
        "        in_channels=IN_CHANNELS,      # ✅ 1 channel now\n",
        "        classes=N_CLASSES,\n",
        "        # slimmer decoder to save VRAM\n",
        "        decoder_channels=(192, 128, 64, 32, 16),\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Validation (full volume)\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def validate_full_volume(model, val_items, device):\n",
        "    model.eval()\n",
        "\n",
        "    mean_dice_all = []          # mean of classes 1-3\n",
        "    per_class_dice = {1: [], 2: [], 3: []}\n",
        "\n",
        "    for it in tqdm(val_items, desc=\"Validating (full-volume)\", leave=False):\n",
        "        vol = load_nifti_image_chwd(it[\"image\"])      # C D H W (C=1 now)\n",
        "        lab = load_nifti_label_dhw(it[\"label\"])       # D H W\n",
        "\n",
        "        pred, _ = sliding_window_inference(vol, model, PATCH_SIZE, OVERLAP, device)\n",
        "\n",
        "        dices = dice_per_class(pred.cpu(), torch.from_numpy(lab))\n",
        "        mean_dice_all.append(np.mean(dices[1:]))\n",
        "\n",
        "        for cls in [1, 2, 3]:\n",
        "            per_class_dice[cls].append(float(dices[cls]))\n",
        "\n",
        "    final_mean_dice = float(np.mean(mean_dice_all))\n",
        "    final_per_class_dice = {\n",
        "        cls: float(np.mean(per_class_dice[cls])) for cls in [1, 2, 3]\n",
        "    }\n",
        "\n",
        "    return final_mean_dice, final_per_class_dice\n",
        "\n",
        "def save_checkpoint(path, epoch, model, opt, sched, scaler, best_val):\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": opt.state_dict(),\n",
        "            \"scheduler\": sched.state_dict() if sched is not None else {},\n",
        "            \"scaler\": scaler.state_dict(),\n",
        "            \"best_val\": float(best_val),\n",
        "            \"config\": {\n",
        "                \"encoder\": \"efficientnet-b7\",\n",
        "                \"in_channels\": IN_CHANNELS,\n",
        "                \"classes\": N_CLASSES,\n",
        "                \"patch_size\": PATCH_SIZE,\n",
        "            },\n",
        "        },\n",
        "        path,\n",
        "    )\n",
        "\n",
        "def resume_if_possible(model, opt, sched, scaler, load_scheduler=False):\n",
        "    \"\"\"Load last.pt if it exists and return (start_epoch, best_val).\"\"\"\n",
        "    last_ckpt = os.path.join(SAVE_DIR, \"last.pt\")\n",
        "    if os.path.exists(last_ckpt):\n",
        "        ckpt = torch.load(last_ckpt, map_location=\"cpu\")\n",
        "\n",
        "        # weights\n",
        "        model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "        # optimizer\n",
        "        if \"optimizer\" in ckpt:\n",
        "            opt.load_state_dict(ckpt[\"optimizer\"])\n",
        "\n",
        "        # scheduler (optional)\n",
        "        if load_scheduler and \"scheduler\" in ckpt and sched is not None:\n",
        "            try:\n",
        "                sched.load_state_dict(ckpt[\"scheduler\"])\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ Skipping scheduler state load:\", e)\n",
        "\n",
        "        # scaler\n",
        "        if \"scaler\" in ckpt:\n",
        "            scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "\n",
        "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "        best_val = float(ckpt.get(\"best_val\", -1.0))\n",
        "        print(f\"↩ Resumed from {last_ckpt}: start_epoch={start_epoch}, best_val={best_val:.4f}\")\n",
        "        return start_epoch, best_val\n",
        "    return 1, -1.0\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Train loop\n",
        "# -------------------------\n",
        "def train():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    # 3-way split: train / val / test (reused from 4-mod split)\n",
        "    train_items, val_items, test_items = load_train_val_from_json(JSON_PATH, train_frac=0.75, val_frac=0.05)\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "\n",
        "    train_ds = BratsTrainPatches(train_items)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                              num_workers=NUM_WORKERS, pin_memory=(device==\"cuda\"), drop_last=True)\n",
        "\n",
        "    model = build_model(device)\n",
        "    loss_fn = CEDice(w_ce=1.0, w_dice=1.0, include_bg_dice=False)\n",
        "    cls_w = torch.tensor([1.0, 2.0, 2.3, 1.2], device=device)\n",
        "    loss_fn.ce = nn.CrossEntropyLoss(weight=cls_w, label_smoothing=0.03)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    sched = None\n",
        "    scaler = GradScaler(device=\"cuda\")\n",
        "\n",
        "    start_epoch, best_val = resume_if_possible(model, opt, sched, scaler, load_scheduler=False)\n",
        "\n",
        "    # ---- Build OneCycleLR for the remaining epochs (same as your 4-mod script) ----\n",
        "    steps_per_epoch = len(train_loader) // ACCUM_STEPS\n",
        "    remaining_epochs = max(1, EPOCHS - (start_epoch - 1))\n",
        "\n",
        "    for pg in opt.param_groups:\n",
        "        pg['lr'] = LR\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        opt,\n",
        "        max_lr=LR,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=remaining_epochs,\n",
        "        pct_start=0.1,\n",
        "        div_factor=10,\n",
        "        final_div_factor=100,\n",
        "    )\n",
        "\n",
        "    # ---- init or load training history ----\n",
        "    history_path = os.path.join(SAVE_DIR, \"training_history.json\")\n",
        "    if os.path.exists(history_path):\n",
        "        with open(history_path, \"r\") as f:\n",
        "            history = json.load(f)\n",
        "    else:\n",
        "        history = {\n",
        "            \"epoch\": [],\n",
        "            \"train_loss\": [],\n",
        "            \"val_mean_dice\": [],\n",
        "            \"dice_edema\": [],\n",
        "            \"dice_non_enh\": [],\n",
        "            \"dice_enh\": [],\n",
        "            \"lr\": []\n",
        "        }\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(start_epoch, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "        running = 0.0\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        for i, (x, y) in enumerate(pbar):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(device_type=\"cuda\"):\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y) / ACCUM_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if ((i+1) % ACCUM_STEPS) == 0:\n",
        "                scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True)\n",
        "                sched.step()\n",
        "\n",
        "            running += loss.item() * ACCUM_STEPS\n",
        "            pbar.set_postfix(loss=f\"{(running/(i+1)):.4f}\")\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        train_loss = running / max(1, len(train_loader))\n",
        "\n",
        "        # --- Validation ---\n",
        "        val_mean_dice, per_class = validate_full_volume(model, val_items, device)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        print(f\"[{epoch:03d}] \"\n",
        "              f\"train_loss={train_loss:.4f}  \"\n",
        "              f\"val_meanDice(no-bg)={val_mean_dice:.4f}  \"\n",
        "              f\"Dice(edema)={per_class[1]:.4f}  \"\n",
        "              f\"Dice(non-enh)={per_class[2]:.4f}  \"\n",
        "              f\"Dice(enh)={per_class[3]:.4f}  \"\n",
        "              f\"lr={sched.get_last_lr()[0]:.2e}  ({dt:.1f}s)\")\n",
        "\n",
        "        # ---- Save training history ----\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_mean_dice\"].append(val_mean_dice)\n",
        "        history[\"dice_edema\"].append(per_class[1])\n",
        "        history[\"dice_non_enh\"].append(per_class[2])\n",
        "        history[\"dice_enh\"].append(per_class[3])\n",
        "        history[\"lr\"].append(sched.get_last_lr()[0])\n",
        "\n",
        "        with open(history_path, \"w\") as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        # save last (full training state)\n",
        "        save_checkpoint(\n",
        "            os.path.join(SAVE_DIR, \"last.pt\"),\n",
        "            epoch, model, opt, sched, scaler, best_val\n",
        "        )\n",
        "\n",
        "        # save best (also full state so you can deploy or resume from best)\n",
        "        if val_mean_dice > best_val:\n",
        "            best_val = val_mean_dice\n",
        "            best_path = os.path.join(SAVE_DIR, f\"best_epoch{epoch}_dice{best_val:.4f}.pt\")\n",
        "            save_checkpoint(best_path, epoch, model, opt, sched, scaler, best_val)\n",
        "            print(\"✔ Saved\", best_path)\n",
        "\n",
        "    print(f\"Best val mean Dice (no-bg): {best_val:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxIodN-CzrRG",
        "outputId": "18d97232-b570-4c04-915a-e0c9db2b86b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loaded existing dataset split from /content/drive/MyDrive/BrainTumor_Checkpoints/dataset_split.json\n",
            "Train=363  Val=24  Test=97\n",
            "Train=363  Val=24  Test=97\n",
            "↩ Resumed from /content/drive/MyDrive/BrainTumor_Checkpoints_FLAIR/last.pt: start_epoch=86, best_val=0.5087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/95: 100%|██████████| 60/60 [02:17<00:00,  2.29s/it, loss=0.7694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[086] train_loss=0.7694  val_meanDice(no-bg)=0.4643  Dice(edema)=0.6825  Dice(non-enh)=0.3105  Dice(enh)=0.3999  lr=3.00e-04  (175.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/95: 100%|██████████| 60/60 [02:34<00:00,  2.57s/it, loss=0.7752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[087] train_loss=0.7752  val_meanDice(no-bg)=0.4590  Dice(edema)=0.7113  Dice(non-enh)=0.3273  Dice(enh)=0.3384  lr=2.91e-04  (192.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/95: 100%|██████████| 60/60 [02:38<00:00,  2.64s/it, loss=0.7823]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[088] train_loss=0.7823  val_meanDice(no-bg)=0.4657  Dice(edema)=0.6458  Dice(non-enh)=0.3351  Dice(enh)=0.4163  lr=2.64e-04  (195.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/95: 100%|██████████| 60/60 [02:33<00:00,  2.56s/it, loss=0.7854]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[089] train_loss=0.7854  val_meanDice(no-bg)=0.4507  Dice(edema)=0.7129  Dice(non-enh)=0.3504  Dice(enh)=0.2889  lr=2.24e-04  (194.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/95: 100%|██████████| 60/60 [02:38<00:00,  2.64s/it, loss=0.7867]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[090] train_loss=0.7867  val_meanDice(no-bg)=0.4707  Dice(edema)=0.6926  Dice(non-enh)=0.3793  Dice(enh)=0.3403  lr=1.75e-04  (197.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/95: 100%|██████████| 60/60 [02:34<00:00,  2.57s/it, loss=0.7773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[091] train_loss=0.7773  val_meanDice(no-bg)=0.4796  Dice(edema)=0.6917  Dice(non-enh)=0.3785  Dice(enh)=0.3687  lr=1.23e-04  (192.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/95: 100%|██████████| 60/60 [02:38<00:00,  2.64s/it, loss=0.7666]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[092] train_loss=0.7666  val_meanDice(no-bg)=0.4902  Dice(edema)=0.6998  Dice(non-enh)=0.3667  Dice(enh)=0.4043  lr=7.45e-05  (196.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/95: 100%|██████████| 60/60 [02:35<00:00,  2.59s/it, loss=0.7621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[093] train_loss=0.7621  val_meanDice(no-bg)=0.4867  Dice(edema)=0.7099  Dice(non-enh)=0.3619  Dice(enh)=0.3884  lr=3.48e-05  (193.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/95: 100%|██████████| 60/60 [02:36<00:00,  2.60s/it, loss=0.7550]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[094] train_loss=0.7550  val_meanDice(no-bg)=0.4816  Dice(edema)=0.7178  Dice(non-enh)=0.3639  Dice(enh)=0.3631  lr=9.04e-06  (194.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/95: 100%|██████████| 60/60 [02:34<00:00,  2.57s/it, loss=0.7623]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[095] train_loss=0.7623  val_meanDice(no-bg)=0.4819  Dice(edema)=0.7164  Dice(non-enh)=0.3729  Dice(enh)=0.3563  lr=3.03e-07  (193.8s)\n",
            "Best val mean Dice (no-bg): 0.5087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6"
      ],
      "metadata": {
        "id": "l7TNNY9ehKhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BraTS2024 FLAIR-only (or T2w-only) 3D U-Net\n",
        "\n",
        "import os, json, time, math, random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "import segmentation_models_pytorch_3d as smp3d\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Global config\n",
        "# -----------------------------------------------------------------------------\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# --------- MODALITY SWITCH ----------\n",
        "# Use \"t2f\" for FLAIR-only, later you can change to \"t2w\"\n",
        "MODALITY_NAME = \"t2w\"   # choices: \"t2f\" (FLAIR), \"t2w\" (T2-weighted), etc.\n",
        "# -----------------------------------\n",
        "\n",
        "# Paths (adjust BRATS2024_ROOT to your actual path)\n",
        "BRATS2024_ROOT = \"/content/drive/MyDrive/BraTS2024_TrainingData_extracted/BraTS2024-BraTS-GLI-TrainingData/training_data1_v2\"\n",
        "JSON_PATH = os.path.join(BRATS2024_ROOT, \"dataset_brats2024_cases.json\")\n",
        "\n",
        "\n",
        "# Where to store split file + checkpoints for THIS experiment\n",
        "SAVE_DIR = f\"/content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_{MODALITY_NAME.upper()}\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "#SPLIT_JSON_PATH = os.path.join(SAVE_DIR, \"dataset_split_brats2024.json\")\n",
        "SPLIT_JSON_PATH = \"/content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2F/dataset_split_brats2024.json\"\n",
        "\n",
        "# Compute & memory knobs (similar to before)\n",
        "PATCH_SIZE  = (128, 160, 160)  # or even (128, 144, 144) if you want extra safety\n",
        "OVERLAP     = 0.5              # fine for val/inference\n",
        "BATCH_SIZE  = 2\n",
        "ACCUM_STEPS = 3\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Training schedule\n",
        "EPOCHS = 75\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Data/spec\n",
        "IN_CHANNELS = 1      # single modality (FLAIR or T2w)\n",
        "N_CLASSES   = 4      # 0=bg, 1=ET, 2=NETC, 3=SNFH\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Reproducibility\n",
        "# -----------------------------------------------------------------------------\n",
        "def set_seed(s=SEED):\n",
        "    random.seed(s); np.random.seed(s)\n",
        "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "\n",
        "set_seed()\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# NIfTI I/O + preprocessing\n",
        "# -----------------------------------------------------------------------------\n",
        "def percentile_clip(arr, lo=0.5, hi=99.5):\n",
        "    a = arr.astype(np.float32)\n",
        "    l, h = np.percentile(a, [lo, hi])\n",
        "    a = np.clip(a, l, h)\n",
        "    return a\n",
        "\n",
        "def zscore_per_channel(x, eps=1e-8):\n",
        "    # x: (C, D, H, W)\n",
        "    x = x.astype(np.float32)\n",
        "    for c in range(x.shape[0]):\n",
        "        v = x[c]\n",
        "        mask = (v != 0)\n",
        "        if mask.any():\n",
        "            m = v[mask].mean()\n",
        "            s = v[mask].std()\n",
        "        else:\n",
        "            m = v.mean()\n",
        "            s = v.std()\n",
        "        s = max(float(s), eps)\n",
        "        x[c] = (v - m) / s\n",
        "    return x\n",
        "\n",
        "def load_single_modality_chdw(path_img):\n",
        "    \"\"\"\n",
        "    BraTS2024 modality loader.\n",
        "\n",
        "    Each file is (H, W, D) with a single modality.\n",
        "    We:\n",
        "      - percentile clip\n",
        "      - normalize\n",
        "      - convert to (C=1, D, H, W)\n",
        "    \"\"\"\n",
        "    img = nib.load(str(path_img))\n",
        "    arr = img.get_fdata(dtype=np.float32)   # (H, W, D)\n",
        "    assert arr.ndim == 3, f\"{path_img} shape {arr.shape} not HWD\"\n",
        "\n",
        "    arr = percentile_clip(arr, 0.5, 99.5)     # (H, W, D)\n",
        "    vol = np.transpose(arr, (2, 0, 1))        # (D, H, W)\n",
        "    vol = vol[None, ...]                      # (C=1, D, H, W)\n",
        "    vol = zscore_per_channel(vol)\n",
        "    return vol\n",
        "\n",
        "def load_nifti_label_dhw(path_lab):\n",
        "    \"\"\"\n",
        "    Label loader. Ensures labels are in {0,1,2,3}.\n",
        "    If any label > 3 appears, we map it to 0 (background).\n",
        "    \"\"\"\n",
        "    lab = nib.load(str(path_lab)).get_fdata(dtype=np.float32)  # H, W, D\n",
        "    lab = np.rint(lab).astype(np.int64)\n",
        "    # force into 0..3\n",
        "    lab[lab < 0] = 0\n",
        "    lab[lab > 3] = 0\n",
        "    lab = np.transpose(lab, (2, 0, 1))  # (D, H, W)\n",
        "    return lab\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cropping & Sliding-window inference\n",
        "# -----------------------------------------------------------------------------\n",
        "def random_crop_3d(image_cdhw, label_dhw, crop, tries=8, fg_bias=0.5):\n",
        "    C, D, H, W = image_cdhw.shape\n",
        "    cd, ch, cw = crop\n",
        "    assert D >= cd and H >= ch and W >= cw, f\"Patch {crop} > vol {(D,H,W)}\"\n",
        "    for _ in range(tries):\n",
        "        z0 = np.random.randint(0, D - cd + 1)\n",
        "        y0 = np.random.randint(0, H - ch + 1)\n",
        "        x0 = np.random.randint(0, W - cw + 1)\n",
        "        patch_lab = label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "        if (np.random.rand() > fg_bias) or np.any(patch_lab > 0):\n",
        "            return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], patch_lab\n",
        "    # fallback random\n",
        "    z0 = np.random.randint(0, D - cd + 1)\n",
        "    y0 = np.random.randint(0, H - ch + 1)\n",
        "    x0 = np.random.randint(0, W - cw + 1)\n",
        "    return image_cdhw[:, z0:z0+cd, y0:y0+ch, x0:x0+cw], label_dhw[z0:z0+cd, y0:y0+ch, x0:x0+cw]\n",
        "\n",
        "@torch.no_grad()\n",
        "def sliding_window_inference(volume_cdhw, model, window, overlap, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    C, D, H, W = volume_cdhw.shape\n",
        "    wd, wh, ww = window\n",
        "    sd = max(1, int(wd * (1 - overlap)))\n",
        "    sh = max(1, int(wh * (1 - overlap)))\n",
        "    sw = max(1, int(ww * (1 - overlap)))\n",
        "\n",
        "    out_prob = torch.zeros((N_CLASSES, D, H, W), dtype=torch.float32, device=device)\n",
        "    out_norm = torch.zeros((1, D, H, W), dtype=torch.float32, device=device)\n",
        "\n",
        "    for z in range(0, max(D - wd + 1, 1), sd):\n",
        "        z0 = min(z, D - wd)\n",
        "        for y in range(0, max(H - wh + 1, 1), sh):\n",
        "            y0 = min(y, H - wh)\n",
        "            for x in range(0, max(W - ww + 1, 1), sw):\n",
        "                x0 = min(x, W - ww)\n",
        "                patch = volume_cdhw[:, z0:z0+wd, y0:y0+wh, x0:x0+ww]\n",
        "                pt = torch.from_numpy(patch).unsqueeze(0).to(device)  # 1,C,D,H,W\n",
        "                logits = model(pt)                                    # 1,C,d,h,w\n",
        "                probs = F.softmax(logits, dim=1)[0]\n",
        "                out_prob[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += probs\n",
        "                out_norm[:, z0:z0+wd, y0:y0+wh, x0:x0+ww] += 1.0\n",
        "\n",
        "    out_prob /= (out_norm + 1e-8)\n",
        "    pred = torch.argmax(out_prob, dim=0)  # D,H,W\n",
        "    return pred, out_prob\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Dataset\n",
        "# -----------------------------------------------------------------------------\n",
        "class Brats2024TrainPatches(Dataset):\n",
        "    def __init__(self, items, modality_name=MODALITY_NAME):\n",
        "        self.items = items\n",
        "        self.modality_name = modality_name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        it = self.items[i]\n",
        "\n",
        "        img_path = it[self.modality_name]\n",
        "        lab_path = it[\"seg\"]\n",
        "\n",
        "        assert img_path is not None, f\"{self.modality_name} missing for case {it['case_id']}\"\n",
        "\n",
        "        img = load_single_modality_chdw(img_path)  # (1, D, H, W)\n",
        "        lab = load_nifti_label_dhw(lab_path)       # (D, H, W)\n",
        "\n",
        "        img, lab = random_crop_3d(img, lab, PATCH_SIZE, fg_bias=0.85)\n",
        "\n",
        "        # Rotations in H,W\n",
        "        if np.random.rand() < 0.5:\n",
        "            k = np.random.randint(0, 4)\n",
        "            img = np.rot90(img, k=k, axes=(2, 3)).copy()\n",
        "            lab = np.rot90(lab, k=k, axes=(1, 2)).copy()\n",
        "\n",
        "        # Flips in D,H,W\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=1).copy()\n",
        "            lab = np.flip(lab, axis=0).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=2).copy()\n",
        "            lab = np.flip(lab, axis=1).copy()\n",
        "        if np.random.rand() < 0.33:\n",
        "            img = np.flip(img, axis=3).copy()\n",
        "            lab = np.flip(lab, axis=2).copy()\n",
        "\n",
        "        # Light intensity aug\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img * (0.9 + 0.2 * np.random.rand())\n",
        "        if np.random.rand() < 0.15:\n",
        "            img = img + np.random.normal(0, 0.05, img.shape).astype(np.float32)\n",
        "\n",
        "        return torch.from_numpy(img), torch.from_numpy(lab).long()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Losses & metrics\n",
        "# -----------------------------------------------------------------------------\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0, include_bg=False):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "        self.include_bg = include_bg\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        N, C, D, H, W = probs.shape\n",
        "        onehot = torch.zeros_like(probs)\n",
        "        onehot.scatter_(1, targets.unsqueeze(1), 1)\n",
        "        s = 0 if self.include_bg else 1\n",
        "        p = probs[:, s:, ...]\n",
        "        t = onehot[:, s:, ...]\n",
        "        dims = (0, 2, 3, 4)\n",
        "        inter = torch.sum(p * t, dims)\n",
        "        denom = torch.sum(p + t, dims)\n",
        "        dice = (2.0 * inter + self.smooth) / (denom + self.smooth)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "class CEDice(nn.Module):\n",
        "    def __init__(self, w_ce=1.0, w_dice=1.0, include_bg_dice=False):\n",
        "        super().__init__()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = SoftDiceLoss(include_bg=include_bg_dice)\n",
        "        self.w_ce = w_ce\n",
        "        self.w_dice = w_dice\n",
        "\n",
        "    def forward(self, logits, y):\n",
        "        return self.w_ce * self.ce(logits, y) + self.w_dice * self.dice(logits, y)\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_per_class(pred, target, n_classes=N_CLASSES):\n",
        "    if pred.ndim == 3:\n",
        "        pred = pred.unsqueeze(0)\n",
        "        target = target.unsqueeze(0)\n",
        "    out = []\n",
        "    for c in range(n_classes):\n",
        "        p = (pred == c)\n",
        "        t = (target == c)\n",
        "        inter = (p & t).sum().item()\n",
        "        denom = p.sum().item() + t.sum().item()\n",
        "        out.append((2 * inter / denom) if denom > 0 else 1.0)\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_whole_tumor(pred, target, eps=1e-8):\n",
        "    \"\"\"\n",
        "    pred, target: (D,H,W) int\n",
        "    Dice for \"whole tumor\" = label > 0\n",
        "    \"\"\"\n",
        "    p = (pred > 0)\n",
        "    t = (target > 0)\n",
        "    inter = (p & t).sum().item()\n",
        "    denom = p.sum().item() + t.sum().item()\n",
        "    if denom == 0:\n",
        "        return 1.0\n",
        "    return 2.0 * inter / (denom + eps)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Data split (75% train, 5% val, 20% test)\n",
        "# -----------------------------------------------------------------------------\n",
        "def load_train_val_from_json(json_path, train_frac=0.75, val_frac=0.05):\n",
        "    \"\"\"\n",
        "    If split JSON exists, reload it.\n",
        "    Otherwise:\n",
        "      - read dataset_brats2024_cases.json\n",
        "      - shuffle\n",
        "      - create 75% train / 5% val / 20% test split\n",
        "      - save split JSON in SAVE_DIR\n",
        "    \"\"\"\n",
        "    if os.path.exists(SPLIT_JSON_PATH):\n",
        "        with open(SPLIT_JSON_PATH, \"r\") as f:\n",
        "            split = json.load(f)\n",
        "        train_items = split[\"train\"]\n",
        "        val_items   = split[\"val\"]\n",
        "        test_items  = split[\"test\"]\n",
        "        print(f\"Loaded existing split from {SPLIT_JSON_PATH}\")\n",
        "        print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "        return train_items, val_items, test_items\n",
        "\n",
        "    with open(json_path, \"r\") as f:\n",
        "        js = json.load(f)\n",
        "\n",
        "    items = js[\"training\"]\n",
        "    n = len(items)\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.RandomState(SEED)\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    n_train = int(n * train_frac)\n",
        "    n_val   = int(n * val_frac)\n",
        "    n_test  = n - n_train - n_val\n",
        "\n",
        "    train_idx = idx[:n_train]\n",
        "    val_idx   = idx[n_train:n_train+n_val]\n",
        "    test_idx  = idx[n_train+n_val:]\n",
        "\n",
        "    train_items = [items[int(i)] for i in train_idx]\n",
        "    val_items   = [items[int(i)] for i in val_idx]\n",
        "    test_items  = [items[int(i)] for i in test_idx]\n",
        "\n",
        "    split = {\n",
        "        \"train\": train_items,\n",
        "        \"val\":   val_items,\n",
        "        \"test\":  test_items,\n",
        "    }\n",
        "    with open(SPLIT_JSON_PATH, \"w\") as f:\n",
        "        json.dump(split, f, indent=2)\n",
        "\n",
        "    print(f\"Created new split at {SPLIT_JSON_PATH}\")\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "    return train_items, val_items, test_items\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model\n",
        "# -----------------------------------------------------------------------------\n",
        "def build_model(device):\n",
        "    model = smp3d.Unet(\n",
        "        encoder_name=\"efficientnet-b7\",\n",
        "        encoder_weights=None,\n",
        "        in_channels=IN_CHANNELS,\n",
        "        classes=N_CLASSES,\n",
        "        decoder_channels=(192, 128, 64, 32, 16),\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Validation (full volume, per-class + whole tumor)\n",
        "# -----------------------------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def validate_full_volume(model, val_items, device):\n",
        "    model.eval()\n",
        "\n",
        "    mean_dice_all = []         # mean over classes 1-3\n",
        "    per_class_dice = {1: [], 2: [], 3: []}\n",
        "    whole_dice_list = []\n",
        "\n",
        "    for it in tqdm(val_items, desc=\"Validating (full-volume)\", leave=False):\n",
        "        img_path = it[MODALITY_NAME]\n",
        "        lab_path = it[\"seg\"]\n",
        "\n",
        "        if img_path is None:\n",
        "            continue\n",
        "\n",
        "        vol = load_single_modality_chdw(img_path)  # (1,D,H,W)\n",
        "        lab = load_nifti_label_dhw(lab_path)       # (D,H,W)\n",
        "\n",
        "        pred, _ = sliding_window_inference(vol, model, PATCH_SIZE, OVERLAP, device)\n",
        "\n",
        "        dices = dice_per_class(pred.cpu(), torch.from_numpy(lab))\n",
        "        mean_dice_all.append(np.mean(dices[1:]))\n",
        "\n",
        "        for cls in [1, 2, 3]:\n",
        "            per_class_dice[cls].append(float(dices[cls]))\n",
        "\n",
        "        whole_d = dice_whole_tumor(pred.cpu(), torch.from_numpy(lab))\n",
        "        whole_dice_list.append(float(whole_d))\n",
        "\n",
        "    final_mean_dice = float(np.mean(mean_dice_all)) if mean_dice_all else 0.0\n",
        "    final_per_class_dice = {\n",
        "        cls: float(np.mean(per_class_dice[cls])) if per_class_dice[cls] else 0.0\n",
        "        for cls in [1, 2, 3]\n",
        "    }\n",
        "    final_whole_dice = float(np.mean(whole_dice_list)) if whole_dice_list else 0.0\n",
        "\n",
        "    return final_mean_dice, final_per_class_dice, final_whole_dice\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Checkpoint helpers\n",
        "# -----------------------------------------------------------------------------\n",
        "def save_checkpoint(path, epoch, model, opt, sched, scaler, best_val_whole):\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": opt.state_dict(),\n",
        "            \"scheduler\": sched.state_dict() if sched is not None else {},\n",
        "            \"scaler\": scaler.state_dict(),\n",
        "            \"best_val_whole\": float(best_val_whole),\n",
        "            \"config\": {\n",
        "                \"encoder\": \"efficientnet-b7\",\n",
        "                \"in_channels\": IN_CHANNELS,\n",
        "                \"classes\": N_CLASSES,\n",
        "                \"patch_size\": PATCH_SIZE,\n",
        "                \"modality\": MODALITY_NAME,\n",
        "            },\n",
        "        },\n",
        "        path,\n",
        "    )\n",
        "\n",
        "def resume_if_possible(model, opt, sched, scaler, load_scheduler=False):\n",
        "    \"\"\"\n",
        "    Allow resuming THIS BraTS2024 experiment if last.pt exists in SAVE_DIR.\n",
        "    (Don't reuse old MSD checkpoints.)\n",
        "    \"\"\"\n",
        "    last_ckpt = os.path.join(SAVE_DIR, \"last.pt\")\n",
        "    if os.path.exists(last_ckpt):\n",
        "        ckpt = torch.load(last_ckpt, map_location=\"cpu\")\n",
        "\n",
        "        model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "        if \"optimizer\" in ckpt:\n",
        "            opt.load_state_dict(ckpt[\"optimizer\"])\n",
        "\n",
        "        if load_scheduler and \"scheduler\" in ckpt and sched is not None:\n",
        "            try:\n",
        "                sched.load_state_dict(ckpt[\"scheduler\"])\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ Skipping scheduler state load:\", e)\n",
        "\n",
        "        if \"scaler\" in ckpt:\n",
        "            scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "\n",
        "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "        best_val_whole = float(ckpt.get(\"best_val_whole\", -1.0))\n",
        "        print(f\"↩ Resumed from {last_ckpt}: start_epoch={start_epoch}, best_wholeDice={best_val_whole:.4f}\")\n",
        "        return start_epoch, best_val_whole\n",
        "\n",
        "    return 1, -1.0\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Train loop\n",
        "# -----------------------------------------------------------------------------\n",
        "def train():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "    print(\"Modality:\", MODALITY_NAME)\n",
        "\n",
        "    train_items, val_items, test_items = load_train_val_from_json(JSON_PATH, train_frac=0.75, val_frac=0.05)\n",
        "    print(f\"Train={len(train_items)}  Val={len(val_items)}  Test={len(test_items)}\")\n",
        "\n",
        "    train_ds = Brats2024TrainPatches(train_items, modality_name=MODALITY_NAME)\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=(device == \"cuda\"),\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    model = build_model(device)\n",
        "    loss_fn = CEDice(w_ce=1.0, w_dice=1.0, include_bg_dice=False)\n",
        "    cls_w = torch.tensor([1.0, 2.0, 2.3, 1.2], device=device)\n",
        "    loss_fn.ce = nn.CrossEntropyLoss(weight=cls_w, label_smoothing=0.03)\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    sched = None\n",
        "    scaler = GradScaler(device=\"cuda\" if device == \"cuda\" else \"cpu\")\n",
        "\n",
        "    start_epoch, best_val_whole = resume_if_possible(model, opt, sched, scaler, load_scheduler=False)\n",
        "\n",
        "    # OneCycleLR, same style as before\n",
        "    steps_per_epoch = max(1, len(train_loader) // ACCUM_STEPS)\n",
        "    remaining_epochs = max(1, EPOCHS - (start_epoch - 1))\n",
        "\n",
        "    for pg in opt.param_groups:\n",
        "        pg[\"lr\"] = LR\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        opt,\n",
        "        max_lr=LR,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=remaining_epochs,\n",
        "        pct_start=0.1,\n",
        "        div_factor=10,\n",
        "        final_div_factor=100,\n",
        "    )\n",
        "\n",
        "    # training history\n",
        "    history_path = os.path.join(SAVE_DIR, \"training_history.json\")\n",
        "    if os.path.exists(history_path):\n",
        "        with open(history_path, \"r\") as f:\n",
        "            history = json.load(f)\n",
        "    else:\n",
        "        history = {\n",
        "            \"epoch\": [],\n",
        "            \"train_loss\": [],\n",
        "            \"val_mean_dice\": [],\n",
        "            \"val_whole_dice\": [],\n",
        "            \"dice_ET\": [],\n",
        "            \"dice_NETC\": [],\n",
        "            \"dice_SNFH\": [],\n",
        "            \"lr\": [],\n",
        "        }\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(start_epoch, EPOCHS + 1):\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "        running = 0.0\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        for i, (x, y) in enumerate(pbar):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(device_type=\"cuda\" if device == \"cuda\" else \"cpu\"):\n",
        "                logits = model(x)\n",
        "                loss = loss_fn(logits, y) / ACCUM_STEPS\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if ((i + 1) % ACCUM_STEPS) == 0:\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                sched.step()\n",
        "\n",
        "            running += loss.item() * ACCUM_STEPS\n",
        "            pbar.set_postfix(loss=f\"{(running / (i + 1)):.4f}\")\n",
        "            step += 1\n",
        "\n",
        "        train_loss = running / max(1, len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        val_mean_dice, per_class, val_whole_dice = validate_full_volume(model, val_items, device)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        print(\n",
        "            f\"[{epoch:03d}] \"\n",
        "            f\"train_loss={train_loss:.4f}  \"\n",
        "            f\"val_meanDice(no-bg)={val_mean_dice:.4f}  \"\n",
        "            f\"Dice(ET)={per_class[1]:.4f}  \"\n",
        "            f\"Dice(NETC)={per_class[2]:.4f}  \"\n",
        "            f\"Dice(SNFH)={per_class[3]:.4f}  \"\n",
        "            f\"wholeDice(label>0)={val_whole_dice:.4f}  \"\n",
        "            f\"lr={sched.get_last_lr()[0]:.2e}  ({dt:.1f}s)\"\n",
        "        )\n",
        "\n",
        "        # history\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_mean_dice\"].append(val_mean_dice)\n",
        "        history[\"val_whole_dice\"].append(val_whole_dice)\n",
        "        history[\"dice_ET\"].append(per_class[1])\n",
        "        history[\"dice_NETC\"].append(per_class[2])\n",
        "        history[\"dice_SNFH\"].append(per_class[3])\n",
        "        history[\"lr\"].append(sched.get_last_lr()[0])\n",
        "\n",
        "        with open(history_path, \"w\") as f:\n",
        "            json.dump(history, f, indent=2)\n",
        "\n",
        "        # save last\n",
        "        save_checkpoint(\n",
        "            os.path.join(SAVE_DIR, \"last.pt\"),\n",
        "            epoch,\n",
        "            model,\n",
        "            opt,\n",
        "            sched,\n",
        "            scaler,\n",
        "            best_val_whole,\n",
        "        )\n",
        "\n",
        "        # save best based on whole-tumor dice\n",
        "        if val_whole_dice > best_val_whole:\n",
        "            best_val_whole = val_whole_dice\n",
        "            best_path = os.path.join(SAVE_DIR, f\"best_epoch{epoch}_wholeDice{best_val_whole:.4f}.pt\")\n",
        "            save_checkpoint(best_path, epoch, model, opt, sched, scaler, best_val_whole)\n",
        "            print(\"✔ Saved\", best_path)\n",
        "\n",
        "    print(f\"Best val whole-tumor Dice: {best_val_whole:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "metadata": {
        "id": "FO5ZIDJpltSE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d1c17cc-5259-4aeb-f6f4-d6fd2649602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Modality: t2w\n",
            "Loaded existing split from /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2F/dataset_split_brats2024.json\n",
            "Train=1012  Val=67  Test=271\n",
            "Train=1012  Val=67  Test=271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/75: 100%|██████████| 506/506 [21:22<00:00,  2.54s/it, loss=1.8527]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001] train_loss=1.8527  val_meanDice(no-bg)=0.3758  Dice(ET)=0.4478  Dice(NETC)=0.3364  Dice(SNFH)=0.3433  wholeDice(label>0)=0.3683  lr=4.17e-05  (1535.9s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch1_wholeDice0.3683.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/75: 100%|██████████| 506/506 [16:15<00:00,  1.93s/it, loss=1.2946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[002] train_loss=1.2946  val_meanDice(no-bg)=0.4347  Dice(ET)=0.6418  Dice(NETC)=0.3190  Dice(SNFH)=0.3433  wholeDice(label>0)=0.3449  lr=7.47e-05  (1059.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=1.1461]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[003] train_loss=1.1461  val_meanDice(no-bg)=0.4949  Dice(ET)=0.6418  Dice(NETC)=0.4997  Dice(SNFH)=0.3433  wholeDice(label>0)=0.5267  lr=1.23e-04  (1066.4s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch3_wholeDice0.5267.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/75: 100%|██████████| 506/506 [16:25<00:00,  1.95s/it, loss=1.1082]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[004] train_loss=1.1082  val_meanDice(no-bg)=0.4966  Dice(ET)=0.6418  Dice(NETC)=0.5049  Dice(SNFH)=0.3433  wholeDice(label>0)=0.5281  lr=1.79e-04  (1071.1s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch4_wholeDice0.5281.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=1.0932]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[005] train_loss=1.0932  val_meanDice(no-bg)=0.4680  Dice(ET)=0.5137  Dice(NETC)=0.5471  Dice(SNFH)=0.3433  wholeDice(label>0)=0.5796  lr=2.33e-04  (1068.3s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch5_wholeDice0.5796.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=1.0866]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[006] train_loss=1.0866  val_meanDice(no-bg)=0.4802  Dice(ET)=0.6119  Dice(NETC)=0.5003  Dice(SNFH)=0.3284  wholeDice(label>0)=0.5334  lr=2.74e-04  (1070.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/75: 100%|██████████| 506/506 [16:19<00:00,  1.94s/it, loss=1.0714]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[007] train_loss=1.0714  val_meanDice(no-bg)=0.4401  Dice(ET)=0.5970  Dice(NETC)=0.5702  Dice(SNFH)=0.1532  wholeDice(label>0)=0.5966  lr=2.97e-04  (1063.5s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch7_wholeDice0.5966.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=1.0621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[008] train_loss=1.0621  val_meanDice(no-bg)=0.4921  Dice(ET)=0.6418  Dice(NETC)=0.5683  Dice(SNFH)=0.2662  wholeDice(label>0)=0.6035  lr=3.00e-04  (1062.9s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch8_wholeDice0.6035.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/75: 100%|██████████| 506/506 [16:16<00:00,  1.93s/it, loss=1.0567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[009] train_loss=1.0567  val_meanDice(no-bg)=0.4933  Dice(ET)=0.6418  Dice(NETC)=0.5867  Dice(SNFH)=0.2515  wholeDice(label>0)=0.6178  lr=3.00e-04  (1063.0s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch9_wholeDice0.6178.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/75: 100%|██████████| 506/506 [16:16<00:00,  1.93s/it, loss=1.0419]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[010] train_loss=1.0419  val_meanDice(no-bg)=0.4588  Dice(ET)=0.6418  Dice(NETC)=0.5738  Dice(SNFH)=0.1607  wholeDice(label>0)=0.6165  lr=2.99e-04  (1062.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/75: 100%|██████████| 506/506 [16:16<00:00,  1.93s/it, loss=1.0360]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[011] train_loss=1.0360  val_meanDice(no-bg)=0.5077  Dice(ET)=0.6418  Dice(NETC)=0.5945  Dice(SNFH)=0.2869  wholeDice(label>0)=0.6275  lr=2.98e-04  (1061.3s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch11_wholeDice0.6275.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=1.0340]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[012] train_loss=1.0340  val_meanDice(no-bg)=0.5013  Dice(ET)=0.6269  Dice(NETC)=0.5929  Dice(SNFH)=0.2842  wholeDice(label>0)=0.6337  lr=2.97e-04  (1063.8s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch12_wholeDice0.6337.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=1.0233]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[013] train_loss=1.0233  val_meanDice(no-bg)=0.4510  Dice(ET)=0.4926  Dice(NETC)=0.5864  Dice(SNFH)=0.2740  wholeDice(label>0)=0.6223  lr=2.95e-04  (1064.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/75: 100%|██████████| 506/506 [16:19<00:00,  1.94s/it, loss=1.0204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[014] train_loss=1.0204  val_meanDice(no-bg)=0.5087  Dice(ET)=0.6119  Dice(NETC)=0.5773  Dice(SNFH)=0.3368  wholeDice(label>0)=0.6102  lr=2.93e-04  (1065.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/75: 100%|██████████| 506/506 [16:19<00:00,  1.94s/it, loss=1.0124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[015] train_loss=1.0124  val_meanDice(no-bg)=0.5184  Dice(ET)=0.6058  Dice(NETC)=0.5924  Dice(SNFH)=0.3571  wholeDice(label>0)=0.6194  lr=2.91e-04  (1065.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=1.0095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[016] train_loss=1.0095  val_meanDice(no-bg)=0.4747  Dice(ET)=0.4867  Dice(NETC)=0.6002  Dice(SNFH)=0.3372  wholeDice(label>0)=0.6301  lr=2.88e-04  (1063.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/75: 100%|██████████| 506/506 [16:18<00:00,  1.93s/it, loss=1.0099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[017] train_loss=1.0099  val_meanDice(no-bg)=0.4985  Dice(ET)=0.5533  Dice(NETC)=0.6024  Dice(SNFH)=0.3397  wholeDice(label>0)=0.6308  lr=2.86e-04  (1066.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=0.9996]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[018] train_loss=0.9996  val_meanDice(no-bg)=0.4385  Dice(ET)=0.4541  Dice(NETC)=0.6014  Dice(SNFH)=0.2599  wholeDice(label>0)=0.6251  lr=2.82e-04  (1065.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/75: 100%|██████████| 506/506 [16:17<00:00,  1.93s/it, loss=1.0028]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[019] train_loss=1.0028  val_meanDice(no-bg)=0.4465  Dice(ET)=0.3875  Dice(NETC)=0.6157  Dice(SNFH)=0.3363  wholeDice(label>0)=0.6525  lr=2.79e-04  (1064.5s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch19_wholeDice0.6525.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/75: 100%|██████████| 506/506 [16:22<00:00,  1.94s/it, loss=0.9970]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[020] train_loss=0.9970  val_meanDice(no-bg)=0.4673  Dice(ET)=0.4636  Dice(NETC)=0.5944  Dice(SNFH)=0.3441  wholeDice(label>0)=0.6258  lr=2.75e-04  (1067.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/75: 100%|██████████| 506/506 [16:20<00:00,  1.94s/it, loss=0.9937]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[021] train_loss=0.9937  val_meanDice(no-bg)=0.4314  Dice(ET)=0.3656  Dice(NETC)=0.5882  Dice(SNFH)=0.3406  wholeDice(label>0)=0.6386  lr=2.71e-04  (1067.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=0.9967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[022] train_loss=0.9967  val_meanDice(no-bg)=0.5123  Dice(ET)=0.5412  Dice(NETC)=0.6266  Dice(SNFH)=0.3691  wholeDice(label>0)=0.6535  lr=2.67e-04  (1069.6s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch22_wholeDice0.6535.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/75: 100%|██████████| 506/506 [16:24<00:00,  1.95s/it, loss=0.9883]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[023] train_loss=0.9883  val_meanDice(no-bg)=0.3885  Dice(ET)=0.2912  Dice(NETC)=0.6102  Dice(SNFH)=0.2640  wholeDice(label>0)=0.6471  lr=2.63e-04  (1071.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/75: 100%|██████████| 506/506 [16:24<00:00,  1.95s/it, loss=0.9894]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[024] train_loss=0.9894  val_meanDice(no-bg)=0.4313  Dice(ET)=0.3429  Dice(NETC)=0.6106  Dice(SNFH)=0.3404  wholeDice(label>0)=0.6505  lr=2.58e-04  (1070.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/75: 100%|██████████| 506/506 [16:24<00:00,  1.95s/it, loss=0.9847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[025] train_loss=0.9847  val_meanDice(no-bg)=0.4288  Dice(ET)=0.3561  Dice(NETC)=0.6129  Dice(SNFH)=0.3174  wholeDice(label>0)=0.6452  lr=2.53e-04  (1070.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/75: 100%|██████████| 506/506 [16:24<00:00,  1.95s/it, loss=0.9836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[026] train_loss=0.9836  val_meanDice(no-bg)=0.4446  Dice(ET)=0.4004  Dice(NETC)=0.5575  Dice(SNFH)=0.3760  wholeDice(label>0)=0.6109  lr=2.48e-04  (1072.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/75: 100%|██████████| 506/506 [16:24<00:00,  1.95s/it, loss=0.9843]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[027] train_loss=0.9843  val_meanDice(no-bg)=0.4652  Dice(ET)=0.4312  Dice(NETC)=0.6230  Dice(SNFH)=0.3413  wholeDice(label>0)=0.6619  lr=2.42e-04  (1073.6s)\n",
            "✔ Saved /content/drive/MyDrive/BrainTumor_Checkpoints_BraTS2024_T2W/best_epoch27_wholeDice0.6619.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=0.9799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[028] train_loss=0.9799  val_meanDice(no-bg)=0.4504  Dice(ET)=0.3871  Dice(NETC)=0.6127  Dice(SNFH)=0.3513  wholeDice(label>0)=0.6513  lr=2.37e-04  (1069.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=0.9763]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[029] train_loss=0.9763  val_meanDice(no-bg)=0.5018  Dice(ET)=0.5403  Dice(NETC)=0.6349  Dice(SNFH)=0.3304  wholeDice(label>0)=0.6615  lr=2.31e-04  (1071.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/75: 100%|██████████| 506/506 [16:24<00:00,  1.94s/it, loss=0.9756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[030] train_loss=0.9756  val_meanDice(no-bg)=0.5060  Dice(ET)=0.5183  Dice(NETC)=0.6185  Dice(SNFH)=0.3811  wholeDice(label>0)=0.6533  lr=2.25e-04  (1073.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/75: 100%|██████████| 506/506 [16:23<00:00,  1.94s/it, loss=0.9712]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[031] train_loss=0.9712  val_meanDice(no-bg)=0.4890  Dice(ET)=0.4972  Dice(NETC)=0.6166  Dice(SNFH)=0.3531  wholeDice(label>0)=0.6514  lr=2.19e-04  (1071.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/75: 100%|██████████| 506/506 [16:24<00:00,  1.94s/it, loss=0.9703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[032] train_loss=0.9703  val_meanDice(no-bg)=0.4802  Dice(ET)=0.4615  Dice(NETC)=0.6292  Dice(SNFH)=0.3497  wholeDice(label>0)=0.6590  lr=2.13e-04  (1073.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/75: 100%|██████████| 506/506 [16:24<00:00,  1.94s/it, loss=0.9670]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[033] train_loss=0.9670  val_meanDice(no-bg)=0.4811  Dice(ET)=0.4686  Dice(NETC)=0.6326  Dice(SNFH)=0.3422  wholeDice(label>0)=0.6615  lr=2.06e-04  (1069.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/75: 100%|██████████| 506/506 [16:20<00:00,  1.94s/it, loss=0.9684]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[034] train_loss=0.9684  val_meanDice(no-bg)=0.4184  Dice(ET)=0.3828  Dice(NETC)=0.5973  Dice(SNFH)=0.2750  wholeDice(label>0)=0.6471  lr=2.00e-04  (1065.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/75:   3%|▎         | 13/506 [00:41<26:09,  3.18s/it, loss=0.9875]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2953299535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2953299535.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mrunning\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mACCUM_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{(running / (i + 1)):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}